<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ML Algorithms Reference Guide</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <style>
        :root {
            --primary: #2c3e50;
            --secondary: #3498db;
            --accent: #e74c3c;
            --light: #ecf0f1;
            --dark: #2c3e50;
            --success: #2ecc71;
            --warning: #f39c12;
            --info: #3498db;
        }
        
        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }
        
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: 20px;
            max-width: 1200px;
            margin: 0 auto;
        }
        
        header {
            text-align: center;
            margin-bottom: 30px;
            padding: 20px;
            background: white;
            border-radius: 10px;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
        }
        
        h1 {
            color: var(--primary);
            margin-bottom: 10px;
            font-size: 2.5rem;
        }
        
        .subtitle {
            color: #666;
            font-size: 1.2rem;
        }
        
        .tabs {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            justify-content: center;
            margin-bottom: 30px;
        }
        
        .tab-btn {
            padding: 12px 20px;
            background: #f1f3f5;
            border: none;
            border-radius: 30px;
            cursor: pointer;
            transition: all 0.3s;
            font-weight: 500;
            display: flex;
            align-items: center;
            gap: 8px;
        }
        
        .tab-btn:hover {
            background: #e1e5e9;
        }
        
        .tab-btn.active {
            background: var(--primary);
            color: white;
        }
        
        .guide-container {
            background-color: white;
            border-radius: 10px;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.08);
            padding: 25px;
            margin-bottom: 30px;
            display: none;
            animation: fadeIn 0.5s ease;
        }
        
        .guide-container.active {
            display: block;
        }
        
        h2 {
            background: linear-gradient(90deg, var(--primary) 0%, var(--secondary) 100%);
            color: white;
            padding: 12px 20px;
            border-radius: 8px;
            margin-top: 0;
            margin-bottom: 20px;
            display: flex;
            align-items: center;
            font-size: 1.5rem;
        }
        
        h2 i {
            margin-right: 10px;
            font-size: 1.3rem;
        }
        
        .guide-content {
            display: grid;
            grid-template-columns: 1fr;
            gap: 25px;
        }
        
        .guide-section {
            background: #f8f9fa;
            border-radius: 10px;
            padding: 20px;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.08);
            border-left: 4px solid var(--secondary);
        }
        
        .guide-section h3 {
            color: var(--primary);
            margin-bottom: 15px;
            display: flex;
            align-items: center;
            gap: 10px;
        }
        
        .guide-section h3 i {
            color: var(--secondary);
        }
        
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 15px 0;
        }
        
        th, td {
            padding: 12px 15px;
            text-align: left;
            border: 1px solid #ddd;
        }
        
        th {
            background: linear-gradient(90deg, var(--secondary) 0%, #5dade2 100%);
            color: white;
            font-weight: 600;
        }
        
        tr:nth-child(even) {
            background-color: #f2f2f2;
        }
        
        .math-formula {
            background: #2d2d2d;
            color: white;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
            overflow-x: auto;
            font-family: 'Courier New', monospace;
        }
        
        .code-example {
            background: #2d2d2d;
            color: white;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
            overflow-x: auto;
            font-family: 'Courier New', monospace;
        }
        
        .applications-grid {
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(300px, 1fr));
            gap: 20px;
            margin-top: 15px;
        }
        
        .application-card {
            background: white;
            border-radius: 8px;
            padding: 15px;
            box-shadow: 0 3px 10px rgba(0, 0, 0, 0.08);
            border-top: 4px solid var(--info);
        }
        
        .application-card h4 {
            color: var(--primary);
            margin-bottom: 10px;
            display: flex;
            align-items: center;
            gap: 8px;
        }
        
        .tips-container {
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(300px, 1fr));
            gap: 20px;
            margin-top: 15px;
        }
        
        .professional-tips, .student-tips {
            background: white;
            border-radius: 8px;
            padding: 15px;
            box-shadow: 0 3px 10px rgba(0, 0, 0, 0.08);
        }
        
        .professional-tips {
            border-top: 4px solid var(--success);
        }
        
        .student-tips {
            border-top: 4px solid var(--warning);
        }
        
        .professional-tips h4, .student-tips h4 {
            color: var(--primary);
            margin-bottom: 10px;
            display: flex;
            align-items: center;
            gap: 8px;
        }
        
        ul {
            padding-left: 20px;
        }
        
        li {
            margin-bottom: 8px;
        }
        
        footer {
            text-align: center;
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #ddd;
            color: #777;
            font-size: 0.9em;
        }
        
        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }
        
        @media (max-width: 768px) {
            .applications-grid, .tips-container {
                grid-template-columns: 1fr;
            }
            
            .tabs {
                flex-direction: column;
                align-items: center;
            }
            
            .tab-btn {
                width: 100%;
                justify-content: center;
            }
        }
    </style>
</head>
<body>
    <header>
        <h1><i class="fas fa-brain"></i> Machine Learning Algorithms Reference Guide</h1>
        <p class="subtitle">Comprehensive guides for each major ML algorithm category</p>
        
        <div class="tabs">
            <button class="tab-btn active" data-category="linear-regression">
                <i class="fas fa-chart-line"></i> Linear Regression
            </button>
            <button class="tab-btn" data-category="logistic-regression">
                <i class="fas fa-project-diagram"></i> Logistic Regression
            </button>
            <button class="tab-btn" data-category="decision-trees">
                <i class="fas fa-sitemap"></i> Decision Trees
            </button>
            <button class="tab-btn" data-category="svm">
                <i class="fas fa-expand-arrows-alt"></i> SVM
            </button>
            <button class="tab-btn" data-category="clustering">
                <i class="fas fa-object-group"></i> Clustering
            </button>
        </div>
    </header>

    <!-- Linear Regression Guide -->
    <div class="guide-container active" id="linear-regression">
        <h2><i class="fas fa-chart-line"></i> Linear Regression Reference Guide</h2>
        
        <div class="guide-content">
            <div class="guide-section">
                <h3><i class="fas fa-question-circle"></i> What Is Linear Regression?</h3>
                <p>Linear regression is a <strong>predictive modeling technique</strong> used to estimate the relationship between a <strong>dependent variable</strong> (target) and one or more <strong>independent variables</strong> (features). It assumes this relationship is <strong>linear</strong> — meaning the change in output is proportional to the change in input.</p>
            </div>
            
            <div class="guide-section">
                <h3><i class="fas fa-check-circle"></i> When to Use Linear Regression</h3>
                <p>Use it when:</p>
                <ul>
                    <li>Your target is <strong>continuous</strong> (e.g., price, temperature, revenue)</li>
                    <li>The relationship between variables is <strong>approximately linear</strong></li>
                    <li>You want <strong>interpretability</strong> and <strong>speed</strong> in modeling</li>
                </ul>
            </div>
            
            <div class="guide-section">
                <h3><i class="fas fa-project-diagram"></i> Types of Linear Regression</h3>
                <table>
                    <thead>
                        <tr>
                            <th>Type</th>
                            <th>Description</th>
                            <th>Formula</th>
                            <th>Use Case</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>Simple Linear Regression</strong></td>
                            <td>One feature, one target</td>
                            <td>\( y = \beta_0 + \beta_1 x + \varepsilon \)</td>
                            <td>Predicting salary from years of experience</td>
                        </tr>
                        <tr>
                            <td><strong>Multiple Linear Regression</strong></td>
                            <td>Multiple features</td>
                            <td>\( y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_n x_n + \varepsilon \)</td>
                            <td>Estimating house price from size, location, rooms</td>
                        </tr>
                        <tr>
                            <td><strong>Polynomial Regression</strong></td>
                            <td>Non-linear relationship modeled with powers of x</td>
                            <td>\( y = \beta_0 + \beta_1 x + \beta_2 x^2 + \dots + \beta_n x^n + \varepsilon \)</td>
                            <td>Modeling traffic growth or seasonal trends</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            
            <div class="guide-section">
                <h3><i class="fas fa-ruler"></i> Evaluation Metrics</h3>
                <table>
                    <thead>
                        <tr>
                            <th>Metric</th>
                            <th>Formula</th>
                            <th>Purpose</th>
                            <th>Ideal Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>R² (Coefficient of Determination)</strong></td>
                            <td>\( R^2 = 1 - \frac{SS_{res}}{SS_{tot}} \)</td>
                            <td>Explains variance captured by model</td>
                            <td>Close to 1</td>
                        </tr>
                        <tr>
                            <td><strong>MAE (Mean Absolute Error)</strong></td>
                            <td>\( MAE = \frac{1}{n} \sum |y_i - \hat{y}_i| \)</td>
                            <td>Average error magnitude</td>
                            <td>Lower is better</td>
                        </tr>
                        <tr>
                            <td><strong>MSE (Mean Squared Error)</strong></td>
                            <td>\( MSE = \frac{1}{n} \sum (y_i - \hat{y}_i)^2 \)</td>
                            <td>Penalizes large errors</td>
                            <td>Lower is better</td>
                        </tr>
                        <tr>
                            <td><strong>RMSE (Root Mean Squared Error)</strong></td>
                            <td>\( RMSE = \sqrt{MSE} \)</td>
                            <td>Interpretable in same units as target</td>
                            <td>Lower is better</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            
            <div class="guide-section">
                <h3><i class="fas fa-code"></i> Python Code Examples</h3>
                <h4>Simple Linear Regression</h4>
                <div class="code-example">
# Simple Linear Regression<br>
from sklearn.linear_model import LinearRegression<br>
import numpy as np<br><br>
X = np.array([[1], [2], [3], [4], [5]])  # Experience<br>
y = np.array([40, 50, 60, 70, 80])       # Salary in $1000s<br><br>
model = LinearRegression()<br>
model.fit(X, y)<br>
print("Predicted salary for 6 years:", model.predict([[6]])[0])
                </div>
                
                <h4>Multiple Linear Regression</h4>
                <div class="code-example">
# Multiple Linear Regression<br>
X = np.array([<br>
    [1500, 8, 3],<br>
    [1800, 7, 4],<br>
    [2400, 9, 4],<br>
    [3000, 6, 5]<br>
])  # [Size, Location Score, Rooms]<br>
y = np.array([300, 350, 500, 600])  # Price in $1000s<br><br>
model = LinearRegression()<br>
model.fit(X, y)<br>
print("Coefficients:", model.coef_)
                </div>
            </div>
            
            <div class="guide-section">
                <h3><i class="fas fa-globe"></i> Real-World Applications</h3>
                <div class="applications-grid">
                    <div class="application-card">
                        <h4><i class="fas fa-chart-line"></i> Business Analytics</h4>
                        <p>Forecasting revenue based on ad spend and customer acquisition</p>
                    </div>
                    <div class="application-card">
                        <h4><i class="fas fa-truck"></i> Procurement</h4>
                        <p>Predicting vendor delivery time from order complexity</p>
                    </div>
                    <div class="application-card">
                        <h4><i class="fas fa-graduation-cap"></i> Education</h4>
                        <p>Estimating student scores from study hours and attendance</p>
                    </div>
                    <div class="application-card">
                        <h4><i class="fas fa-heartbeat"></i> Healthcare</h4>
                        <p>Modeling blood pressure from age, weight, and salt intake</p>
                    </div>
                </div>
            </div>
            
            <div class="guide-section">
                <h3><i class="fas fa-lightbulb"></i> Strategic Tips</h3>
                <div class="tips-container">
                    <div class="professional-tips">
                        <h4><i class="fas fa-user-tie"></i> For Professionals</h4>
                        <ul>
                            <li>Use <strong>Multiple Regression</strong> for richer insights in dashboards</li>
                            <li>Apply <strong>Polynomial Regression</strong> for modeling growth curves</li>
                            <li>Integrate models into <strong>FastAPI endpoints</strong> for real-time predictions</li>
                            <li>Validate assumptions with <strong>residual plots</strong></li>
                            <li>Use <strong>regularization</strong> for large datasets</li>
                        </ul>
                    </div>
                    <div class="student-tips">
                        <h4><i class="fas fa-user-graduate"></i> For Students</h4>
                        <ul>
                            <li>Start with <strong>visual intuition</strong> — scatter plots help!</li>
                            <li>Learn to interpret <strong>coefficients</strong></li>
                            <li>Practice with <strong>real datasets</strong></li>
                            <li>Understand <strong>overfitting</strong> risks</li>
                            <li>Use <strong>Jupyter Notebooks</strong> for experimentation</li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- Logistic Regression Guide -->
    <div class="guide-container" id="logistic-regression">
        <h2><i class="fas fa-project-diagram"></i> Logistic Regression Reference Guide</h2>
        
        <div class="guide-content">
            <div class="guide-section">
                <h3><i class="fas fa-question-circle"></i> What Is Logistic Regression?</h3>
                <p>Logistic regression is a <strong>classification algorithm</strong> used to predict a binary outcome based on a set of independent variables. It estimates probabilities using a logistic function, which outputs values between 0 and 1.</p>
            </div>
            
            <div class="guide-section">
                <h3><i class="fas fa-check-circle"></i> When to Use Logistic Regression</h3>
                <p>Use it when:</p>
                <ul>
                    <li>Your target is <strong>binary</strong> (e.g., yes/no, true/false, 0/1)</li>
                    <li>You need <strong>probability estimates</strong> for outcomes</li>
                    <li>Interpretability is important for stakeholders</li>
                </ul>
            </div>
            
            <div class="guide-section">
                <h3><i class="fas fa-project-diagram"></i> Key Concepts</h3>
                <table>
                    <thead>
                        <tr>
                            <th>Concept</th>
                            <th>Description</th>
                            <th>Formula</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>Sigmoid Function</strong></td>
                            <td>Maps any real value into the (0, 1) interval</td>
                            <td>\( \sigma(z) = \frac{1}{1 + e^{-z}} \)</td>
                        </tr>
                        <tr>
                            <td><strong>Log Odds</strong></td>
                            <td>Logarithm of the odds of the event occurring</td>
                            <td>\( \log\left(\frac{p}{1-p}\right) = \beta_0 + \beta_1x_1 + \dots + \beta_nx_n \)</td>
                        </tr>
                        <tr>
                            <td><strong>Decision Boundary</strong></td>
                            <td>Threshold (usually 0.5) for classifying predictions</td>
                            <td>If \( p \geq 0.5 \), class 1; else class 0</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            
            <div class="guide-section">
                <h3><i class="fas fa-ruler"></i> Evaluation Metrics</h3>
                <table>
                    <thead>
                        <tr>
                            <th>Metric</th>
                            <th>Description</th>
                            <th>Ideal Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>Accuracy</strong></td>
                            <td>Percentage of correct predictions</td>
                            <td>Higher is better</td>
                        </tr>
                        <tr>
                            <td><strong>Precision</strong></td>
                            <td>True positives / (True positives + False positives)</td>
                            <td>Higher is better</td>
                        </tr>
                        <tr>
                            <td><strong>Recall</strong></td>
                            <td>True positives / (True positives + False negatives)</td>
                            <td>Higher is better</td>
                        </tr>
                        <tr>
                            <td><strong>F1-Score</strong></td>
                            <td>Harmonic mean of precision and recall</td>
                            <td>Higher is better</td>
                        </tr>
                        <tr>
                            <td><strong>ROC-AUC</strong></td>
                            <td>Area under the ROC curve</td>
                            <td>Closer to 1 is better</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            
            <div class="guide-section">
                <h3><i class="fas fa-code"></i> Python Code Examples</h3>
                <div class="code-example">
# Logistic Regression<br>
from sklearn.linear_model import LogisticRegression<br>
from sklearn.model_selection import train_test_split<br>
from sklearn.metrics import accuracy_score, classification_report<br><br>
# Split the data<br>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)<br><br>
# Create and train model<br>
model = LogisticRegression()<br>
model.fit(X_train, y_train)<br><br>
# Make predictions<br>
y_pred = model.predict(X_test)<br>
print("Accuracy:", accuracy_score(y_test, y_pred))<br>
print(classification_report(y_test, y_pred))
                </div>
            </div>
            
            <div class="guide-section">
                <h3><i class="fas fa-globe"></i> Real-World Applications</h3>
                <div class="applications-grid">
                    <div class="application-card">
                        <h4><i class="fas fa-envelope"></i> Spam Detection</h4>
                        <p>Classifying emails as spam or not spam based on content features</p>
                    </div>
                    <div class="application-card">
                        <h4><i class="fas fa-heartbeat"></i> Disease Diagnosis</h4>
                        <p>Predicting whether a patient has a disease based on symptoms</p>
                    </div>
                    <div class="application-card">
                        <h4><i class="fas fa-credit-card"></i> Fraud Detection</h4>
                        <p>Identifying fraudulent transactions based on spending patterns</p>
                    </div>
                    <div class="application-card">
                        <h4><i class="fas fa-thumbs-up"></i> Sentiment Analysis</h4>
                        <p>Classifying text as positive or negative sentiment</p>
                    </div>
                </div>
            </div>
            
            <div class="guide-section">
                <h3><i class="fas fa-lightbulb"></i> Strategic Tips</h3>
                <div class="tips-container">
                    <div class="professional-tips">
                        <h4><i class="fas fa-user-tie"></i> For Professionals</h4>
                        <ul>
                            <li>Use <strong>class weights</strong> for imbalanced datasets</li>
                            <li>Apply <strong>regularization</strong> to prevent overfitting</li>
                            <li>Interpret <strong>coefficients</strong> as log odds ratios</li>
                            <li>Use <strong>probability thresholds</strong> optimized for business needs</li>
                            <li>Combine with <strong>feature engineering</strong> for better performance</li>
                        </ul>
                    </div>
                    <div class="student-tips">
                        <h4><i class="fas fa-user-graduate"></i> For Students</h4>
                        <ul>
                            <li>Understand the <strong>sigmoid function</strong> and its properties</li>
                            <li>Learn how to interpret <strong>odds ratios</strong></li>
                            <li>Practice with <strong>binary classification</strong> datasets</li>
                            <li>Experiment with different <strong>threshold values</strong></li>
                            <li>Compare with other <strong>classification algorithms</strong></li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- Additional algorithm guides would go here -->
    <!-- Decision Trees Guide -->
    <div class="guide-container" id="decision-trees">
        <h2><i class="fas fa-sitemap"></i> Decision Trees Reference Guide</h2>
        
        <div class="guide-content">
            <div class="guide-section">
                <h3><i class="fas fa-question-circle"></i> What Are Decision Trees?</h3>
                
                <div class="definition-box">
                    <h4><i class="fas fa-book"></i> Definition</h4>
                    <p>Decision Trees are <strong>supervised learning algorithms</strong> used for both classification and regression tasks. They create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features. The structure resembles a tree with nodes representing decisions and leaves representing outcomes.</p>
                </div>
                
                <p>Decision trees work by recursively splitting the data into subsets based on the most significant features, creating a tree-like structure where each internal node represents a feature test, each branch represents the outcome of the test, and each leaf node represents a class label or continuous value.</p>
            </div>
            
            <div class="guide-section">
                <h3><i class="fas fa-check-circle"></i> When to Use Decision Trees</h3>
                <p>Use Decision Trees when:</p>
                <ul>
                    <li>You need an <strong>interpretable model</strong> that stakeholders can understand</li>
                    <li>Your data contains both <strong>numerical and categorical features</strong></li>
                    <li>You want to understand <strong>feature importance</strong></li>
                    <li>You're dealing with <strong>non-linear relationships</strong></li>
                    <li>You need a <strong>quick baseline model</strong></li>
                </ul>
            </div>
            
            <div class="guide-section">
                <h3><i class="fas fa-project-diagram"></i> Key Components</h3>
                
                <table>
                    <thead>
                        <tr>
                            <th>Component</th>
                            <th>Description</th>
                            <th>Role</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>Root Node</strong></td>
                            <td>The topmost node that represents the entire dataset</td>
                            <td>Starting point for decision making</td>
                        </tr>
                        <tr>
                            <td><strong>Internal Nodes</strong></td>
                            <td>Nodes that represent feature tests</td>
                            <td>Split data based on feature values</td>
                        </tr>
                        <tr>
                            <td><strong>Branches</strong></td>
                            <td>Connections between nodes</td>
                            <td>Represent outcomes of decisions</td>
                        </tr>
                        <tr>
                            <td><strong>Leaf Nodes</strong></td>
                            <td>Terminal nodes that represent final decisions</td>
                            <td>Contain prediction outcomes</td>
                        </tr>
                        <tr>
                            <td><strong>Splitting</strong></td>
                            <td>Process of dividing nodes</td>
                            <td>Creates homogeneous subsets</td>
                        </tr>
                        <tr>
                            <td><strong>Pruning</strong></td>
                            <td>Removing unnecessary branches</td>
                            <td>Reduces overfitting</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            
            <div class="guide-section">
                <h3><i class="fas fa-calculator"></i> Splitting Criteria</h3>
                
                <h4>Classification Trees</h4>
                <div class="math-formula">
                    // Gini Impurity<br>
                    Gini = 1 - Σ(p_i)²<br><br>
                    
                    // Information Gain (Entropy)<br>
                    Entropy = -Σ(p_i * log₂(p_i))<br>
                    Information Gain = Entropy(parent) - Σ(weight * Entropy(child))
                </div>
                
                <h4>Regression Trees</h4>
                <div class="math-formula">
                    // Variance Reduction<br>
                    Variance = Σ(y_i - μ)² / n<br>
                    Reduction = Variance(parent) - Σ(weight * Variance(child))
                </div>
                
                <table>
                    <thead>
                        <tr>
                            <th>Criterion</th>
                            <th>Type</th>
                            <th>When to Use</th>
                            <th>Characteristics</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>Gini Impurity</strong></td>
                            <td>Classification</td>
                            <td>Default for most implementations</td>
                            <td>Faster computation, similar results to entropy</td>
                        </tr>
                        <tr>
                            <td><strong>Information Gain</strong></td>
                            <td>Classification</td>
                            <td>When you prefer information theory approach</td>
                            <td>More balanced splits, slightly slower</td>
                        </tr>
                        <tr>
                            <td><strong>Variance Reduction</strong></td>
                            <td>Regression</td>
                            <td>For continuous target variables</td>
                            <td>Minimizes squared errors</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            
            <div class="guide-section">
                <h3><i class="fas fa-code-branch"></i> Tree Building Process</h3>
                
                <ol>
                    <li><strong>Start with Root Node:</strong> Begin with the entire dataset</li>
                    <li><strong>Find Best Split:</strong> For each feature, find the best split point</li>
                    <li><strong>Split Data:</strong> Divide data into subsets based on the best split</li>
                    <li><strong>Recurse:</strong> Repeat process for each subset until stopping criteria met</li>
                    <li><strong>Create Leaf Nodes:</strong> Assign predictions to terminal nodes</li>
                </ol>
                
                <div class="definition-box">
                    <h4><i class="fas fa-exclamation-triangle"></i> Stopping Criteria</h4>
                    <ul>
                        <li>Maximum tree depth reached</li>
                        <li>Minimum samples per leaf achieved</li>
                        <li>Minimum samples for split satisfied</li>
                        <li>No improvement in impurity</li>
                        <li>All features are constant</li>
                    </ul>
                </div>
            </div>
            
            <div class="guide-section">
                <h3><i class="fas fa-code"></i> Python Implementation</h3>
                
                <h4>Basic Decision Tree Classifier</h4>
                <div class="code-example">
from sklearn.tree import DecisionTreeClassifier<br>
from sklearn.model_selection import train_test_split<br>
from sklearn.metrics import accuracy_score, classification_report<br>
from sklearn import tree<br>
import matplotlib.pyplot as plt<br><br>

# Load and prepare data<br>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)<br><br>

# Create and train model<br>
dt_classifier = DecisionTreeClassifier(<br>
    &nbsp;&nbsp;&nbsp;&nbsp;criterion='gini',<br>
    &nbsp;&nbsp;&nbsp;&nbsp;max_depth=5,<br>
    &nbsp;&nbsp;&nbsp;&nbsp;min_samples_split=10,<br>
    &nbsp;&nbsp;&nbsp;&nbsp;min_samples_leaf=5,<br>
    &nbsp;&nbsp;&nbsp;&nbsp;random_state=42<br>
)<br><br>

dt_classifier.fit(X_train, y_train)<br><br>

# Make predictions<br>
y_pred = dt_classifier.predict(X_test)<br>
print("Accuracy:", accuracy_score(y_test, y_pred))<br>
print(classification_report(y_test, y_pred))<br><br>

# Visualize the tree<br>
plt.figure(figsize=(12, 8))<br>
tree.plot_tree(dt_classifier, feature_names=feature_names, class_names=class_names, filled=True)<br>
plt.show()
                </div>
                
                <h4>Decision Tree Regressor</h4>
                <div class="code-example">
from sklearn.tree import DecisionTreeRegressor<br>
from sklearn.metrics import mean_squared_error, r2_score<br><br>

# Create and train regression tree<br>
dt_regressor = DecisionTreeRegressor(<br>
    &nbsp;&nbsp;&nbsp;&nbsp;criterion='squared_error',<br>
    &nbsp;&nbsp;&nbsp;&nbsp;max_depth=4,<br>
    &nbsp;&nbsp;&nbsp;&nbsp;min_samples_split=20,<br>
    &nbsp;&nbsp;&nbsp;&nbsp;random_state=42<br>
)<br><br>

dt_regressor.fit(X_train, y_train)<br><br>

# Make predictions and evaluate<br>
y_pred = dt_regressor.predict(X_test)<br>
print("MSE:", mean_squared_error(y_test, y_pred))<br>
print("R² Score:", r2_score(y_test, y_pred))
                </div>
            </div>
            
            <div class="guide-section">
                <h3><i class="fas fa-tachometer-alt"></i> Hyperparameter Tuning</h3>
                
                <table>
                    <thead>
                        <tr>
                            <th>Parameter</th>
                            <th>Description</th>
                            <th>Effect</th>
                            <th>Typical Values</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>max_depth</strong></td>
                            <td>Maximum depth of the tree</td>
                            <td>Controls overfitting</td>
                            <td>3-10 (None for unlimited)</td>
                        </tr>
                        <tr>
                            <td><strong>min_samples_split</strong></td>
                            <td>Minimum samples required to split a node</td>
                            <td>Prevents overfitting on small subsets</td>
                            <td>2-20</td>
                        </tr>
                        <tr>
                            <td><strong>min_samples_leaf</strong></td>
                            <td>Minimum samples required at a leaf node</td>
                            <td>Smooths predictions</td>
                            <td>1-10</td>
                        </tr>
                        <tr>
                            <td><strong>max_features</strong></td>
                            <td>Number of features to consider for best split</td>
                            <td>Adds randomness, reduces variance</td>
                            <td>'sqrt', 'log2', or integer</td>
                        </tr>
                        <tr>
                            <td><strong>min_impurity_decrease</strong></td>
                            <td>Minimum impurity decrease required for split</td>
                            <td>Controls split quality</td>
                            <td>0.0-0.1</td>
                        </tr>
                    </tbody>
                </table>
                
                <div class="code-example">
from sklearn.model_selection import GridSearchCV<br><br>

# Define parameter grid<br>
param_grid = {<br>
    &nbsp;&nbsp;&nbsp;&nbsp;'max_depth': [3, 5, 7, 10, None],<br>
    &nbsp;&nbsp;&nbsp;&nbsp;'min_samples_split': [2, 5, 10],<br>
    &nbsp;&nbsp;&nbsp;&nbsp;'min_samples_leaf': [1, 2, 4],<br>
    &nbsp;&nbsp;&nbsp;&nbsp;'criterion': ['gini', 'entropy']<br>
}<br><br>

# Perform grid search<br>
grid_search = GridSearchCV(<br>
    &nbsp;&nbsp;&nbsp;&nbsp;DecisionTreeClassifier(random_state=42),<br>
    &nbsp;&nbsp;&nbsp;&nbsp;param_grid,<br>
    &nbsp;&nbsp;&nbsp;&nbsp;cv=5,<br>
    &nbsp;&nbsp;&nbsp;&nbsp;scoring='accuracy'<br>
)<br><br>

grid_search.fit(X_train, y_train)<br>
print("Best parameters:", grid_search.best_params_)<br>
print("Best cross-validation score:", grid_search.best_score_)
                </div>
            </div>
            
            <div class="guide-section">
                <h3><i class="fas fa-sitemap"></i> Advanced Decision Tree Variants</h3>
                
                <table>
                    <thead>
                        <tr>
                            <th>Variant</th>
                            <th>Description</th>
                            <th>Advantages</th>
                            <th>Use Cases</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>CART</strong></td>
                            <td>Classification and Regression Trees</td>
                            <td>Handles both classification and regression</td>
                            <td>General purpose problems</td>
                        </tr>
                        <tr>
                            <td><strong>ID3</strong></td>
                            <td>Iterative Dichotomiser 3</td>
                            <td>Uses information gain, simple implementation</td>
                            <td>Educational purposes, small datasets</td>
                        </tr>
                        <tr>
                            <td><strong>C4.5/C5.0</strong></td>
                            <td>Improved version of ID3</td>
                            <td>Handles missing values, continuous features</td>
                            <td>Commercial applications</td>
                        </tr>
                        <tr>
                            <td><strong>CHAID</strong></td>
                            <td>Chi-squared Automatic Interaction Detection</td>
                            <td>Uses chi-square tests, handles categorical data well</td>
                            <td>Marketing research, survey analysis</td>
                        </tr>
                        <tr>
                            <td><strong>MARS</strong></td>
                            <td>Multivariate Adaptive Regression Splines</td>
                            <td>Handles complex non-linear relationships</td>
                            <td>Complex regression problems</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            
            <div class="guide-section">
                <h3><i class="fas fa-globe"></i> Real-World Applications</h3>
                
                <div class="applications-grid">
                    <div class="application-card">
                        <h4><i class="fas fa-stethoscope"></i> Medical Diagnosis</h4>
                        <p>Classifying diseases based on symptoms and test results. Decision trees help doctors understand the reasoning behind diagnoses.</p>
                    </div>
                    <div class="application-card">
                        <h4><i class="fas fa-credit-card"></i> Credit Scoring</h4>
                        <p>Assessing loan applications by evaluating income, credit history, employment status, and other factors.</p>
                    </div>
                    <div class="application-card">
                        <h4><i class="fas fa-shopping-cart"></i> Customer Segmentation</h4>
                        <p>Identifying customer groups based on purchasing behavior, demographics, and preferences for targeted marketing.</p>
                    </div>
                    <div class="application-card">
                        <h4><i class="fas fa-industry"></i> Quality Control</h4>
                        <p>Predicting manufacturing defects based on process parameters and material properties.</p>
                    </div>
                    <div class="application-card">
                        <h4><i class="fas fa-robot"></i> Fraud Detection</h4>
                        <p>Identifying suspicious transactions by analyzing patterns in transaction data and user behavior.</p>
                    </div>
                    <div class="application-card">
                        <h4><i class="fas fa-chart-line"></i> Financial Analysis</h4>
                        <p>Predicting stock prices or market trends based on technical indicators and economic factors.</p>
                    </div>
                </div>
            </div>
            
            <div class="guide-section">
                <h3><i class="fas fa-balance-scale"></i> Pros and Cons</h3>
                
                <div class="comparison-grid">
                    <div class="comparison-card pros">
                        <h4><i class="fas fa-plus-circle"></i> Advantages</h4>
                        <ul>
                            <li><strong>Easy to interpret and visualize</strong></li>
                            <li>Handles both numerical and categorical data</li>
                            <li>Requires little data preprocessing</li>
                            <li>Can model non-linear relationships</li>
                            <li>White box model - decisions are transparent</li>
                            <li>Robust to outliers</li>
                            <li>Performs feature selection automatically</li>
                        </ul>
                    </div>
                    <div class="comparison-card cons">
                        <h4><i class="fas fa-minus-circle"></i> Disadvantages</h4>
                        <ul>
                            <li><strong>Prone to overfitting</strong> without proper constraints</li>
                            <li>Can create biased trees if some classes dominate</li>
                            <li>Small changes in data can lead to different trees</li>
                            <li>Not suitable for complex relationships requiring many splits</li>
                            <li>Struggles with XOR and similar problems</li>
                            <li>Can have high variance</li>
                            <li>Not the most accurate algorithm for many problems</li>
                        </ul>
                    </div>
                </div>
            </div>
            
            <div class="guide-section">
                <h3><i class="fas fa-lightbulb"></i> Strategic Tips</h3>
                
                <div class="tips-container">
                    <div class="professional-tips">
                        <h4><i class="fas fa-user-tie"></i> For Professionals</h4>
                        <ul>
                            <li>Use <strong>pruning techniques</strong> to control tree complexity</li>
                            <li>Combine with <strong>ensemble methods</strong> (Random Forest, Gradient Boosting) for better performance</li>
                            <li>Use <strong>feature importance</strong> scores for feature selection in other models</li>
                            <li>Implement <strong>cost-complexity pruning</strong> for optimal tree size</li>
                            <li>Consider <strong>business constraints</strong> when setting depth limits</li>
                            <li>Use <strong>cross-validation</strong> for reliable hyperparameter tuning</li>
                            <li>Monitor <strong>tree stability</strong> across different data samples</li>
                        </ul>
                    </div>
                    <div class="student-tips">
                        <h4><i class="fas fa-user-graduate"></i> For Students</h4>
                        <ul>
                            <li>Start with <strong>small datasets</strong> to visualize the tree structure</li>
                            <li>Practice calculating <strong>Gini impurity and information gain</strong> manually</li>
                            <li>Experiment with different <strong>stopping criteria</strong></li>
                            <li>Compare <strong>pre-pruning vs post-pruning</strong> techniques</li>
                            <li>Understand the <strong>bias-variance tradeoff</strong> in tree depth</li>
                            <li>Learn to interpret <strong>feature importance</strong> scores</li>
                            <li>Practice <strong>visualizing trees</strong> for better understanding</li>
                        </ul>
                    </div>
                </div>
            </div>
            
            <div class="guide-section">
                <h3><i class="fas fa-exclamation-triangle"></i> Common Pitfalls & Solutions</h3>
                
                <table>
                    <thead>
                        <tr>
                            <th>Pitfall</th>
                            <th>Problem</th>
                            <th>Solution</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>Overfitting</strong></td>
                            <td>Tree captures noise in training data</td>
                            <td>Use pruning, set depth limits, increase min_samples</td>
                        </tr>
                        <tr>
                            <td><strong>Underfitting</strong></td>
                            <td>Tree is too simple to capture patterns</td>
                            <td>Increase max_depth, reduce min_samples</td>
                        </tr>
                        <tr>
                            <td><strong>Unstable Trees</strong></td>
                            <td>Small data changes cause different trees</td>
                            <td>Use ensemble methods, increase min_samples</td>
                        </tr>
                        <tr>
                            <td><strong>Class Imbalance</strong></td>
                            <td>Majority class dominates splits</td>
                            <td>Use class weights, balance dataset</td>
                        </tr>
                        <tr>
                            <td><strong>Feature Bias</strong></td>
                            <td>Continuous features preferred over categorical</td>
                            <td>Use appropriate splitting criteria, feature engineering</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>
    </div>

    <!-- Additional sections would go here -->
    <div class="guide-container" id="svm">
        <h2><i class="fas fa-expand-arrows-alt"></i> SVM Reference Guide</h2>
        <p class="subtitle">Content for SVM guide would go here...</p>
    </div>

    <div class="guide-container" id="clustering">
        <h2><i class="fas fa-object-group"></i> Clustering Reference Guide</h2>
        <p class="subtitle">Content for Clustering guide would go here...</p>
    </div>

    <!-- <footer>
        <p>Created with <i class="fas fa-heart" style="color: #e74c3c;"></i> | Machine Learning Algorithms Reference Guide</p>
    </footer> -->

    <script>
        // Tab functionality
        document.querySelectorAll('.tab-btn').forEach(button => {
            button.addEventListener('click', () => {
                // Remove active class from all buttons and sections
                document.querySelectorAll('.tab-btn').forEach(btn => btn.classList.remove('active'));
                document.querySelectorAll('.guide-container').forEach(section => section.classList.remove('active'));
                
                // Add active class to clicked button
                button.classList.add('active');
                
                // Show corresponding section
                const category = button.getAttribute('data-category');
                document.getElementById(category).classList.add('active');
            });
        });

        // MathJax configuration
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
            }
        };
    </script>



    <div class="guide-container" id="svm">
        <h2><i class="fas fa-expand-arrows-alt"></i> SVM Reference Guide</h2>
        <p class="subtitle">Content for SVM guide would go here...</p>
    </div>



    <div class="guide-container" id="clustering">
        <h2><i class="fas fa-object-group"></i> Clustering Reference Guide</h2>
        <p class="subtitle">Content for Clustering guide would go here...</p>
    </div>

    

    <footer>
        <p>Created with <i class="fas fa-heart" style="color: #e74c3c;"></i> | Machine Learning Algorithms Reference Guide</p>
        <p>Created by Atif Salam with <i class="fas fa-heart" style="color: #e74c3c;"></i> for the ML community</p>
        <p><i class="fas fa-envelope"></i> : atif.salam@gmail.com, <i class="fas fa-mobile"></i> : +92 300 2328737</p>
    </footer>

    <script>
        // Tab functionality
        document.querySelectorAll('.tab-btn').forEach(button => {
            button.addEventListener('click', () => {
                // Remove active class from all buttons and sections
                document.querySelectorAll('.tab-btn').forEach(btn => btn.classList.remove('active'));
                document.querySelectorAll('.guide-container').forEach(section => section.classList.remove('active'));
                
                // Add active class to clicked button
                button.classList.add('active');
                
                // Show corresponding section
                const category = button.getAttribute('data-category');
                document.getElementById(category).classList.add('active');
            });
        });

        // MathJax configuration
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
            }
        };
    </script>

</body>
</html>